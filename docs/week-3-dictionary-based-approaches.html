<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>Chapter 3 Week 3: Dictionary-Based Approaches | PS9594A: Computational Text Analysis</title>

    <meta name="author" content="Dr. Sebastián Vallejo Vera | Western University" />
  
   <meta name="description" content="Code, exercises, and slides for PS9594A: Computational Text Analysis" />
   <meta name="generator" content="placeholder" />
  <meta property="og:title" content="Chapter 3 Week 3: Dictionary-Based Approaches | PS9594A: Computational Text Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Code, exercises, and slides for PS9594A: Computational Text Analysis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Week 3: Dictionary-Based Approaches | PS9594A: Computational Text Analysis" />
  
  <meta name="twitter:description" content="Code, exercises, and slides for PS9594A: Computational Text Analysis" />
  
  <!-- JS -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script>
  <script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script>
    <script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet" />
    <script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script>
    <script src="libs/bs3compat-0.5.0/transition.js"></script>
    <script src="libs/bs3compat-0.5.0/tabs.js"></script>
    <script src="libs/bs3compat-0.5.0/bs3compat.js"></script>
    <link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet" />
    <script src="libs/bs4_book-1.0.0/bs4_book.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script>

  <!-- CSS -->
  <style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
    
</head>

<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book">
    <a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">PS9594A: Computational Text Analysis</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
      </form>

      <nav aria-label="Table of contents">
        <h2>Table of contents</h2>
        <div id="book-toc"></div>

        <div class="book-extra">
          <p><a id="book-repo" href="#">View book source <i class="fab fa-github"></i></a></li></p>
        </div>
      </nav>
    </div>
  </header>

  <main class="col-sm-12 col-md-9 col-lg-7" id="content">
<div id="week-3-dictionary-based-approaches" class="section level1" number="3">
<h1><span class="header-section-number">Chapter 3</span> Week 3: Dictionary-Based Approaches</h1>
<div id="slides-2" class="section level2 unnumbered">
<h2>Slides</h2>
<ul>
<li>4 Dictionary-Based Approaches (<a href="https://github.com/svallejovera/cpa_uwo/blob/main/slides/4%20Dictionary%20Based%20Approaches.pptx">link</a> or in Perusall)</li>
</ul>
</div>
<div id="setup-2" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Setup</h2>
<p>As always, we first load the packages that we’ll be using:</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="week-3-dictionary-based-approaches.html#cb98-1" tabindex="-1"></a><span class="fu">library</span>(tidyverse) <span class="co"># for wrangling data</span></span>
<span id="cb98-2"><a href="week-3-dictionary-based-approaches.html#cb98-2" tabindex="-1"></a><span class="fu">library</span>(tidylog) <span class="co"># to know what we are wrangling</span></span>
<span id="cb98-3"><a href="week-3-dictionary-based-approaches.html#cb98-3" tabindex="-1"></a><span class="fu">library</span>(tidytext) <span class="co"># for &#39;tidy&#39; manipulation of text data</span></span>
<span id="cb98-4"><a href="week-3-dictionary-based-approaches.html#cb98-4" tabindex="-1"></a><span class="fu">library</span>(textdata) <span class="co"># text datasets</span></span>
<span id="cb98-5"><a href="week-3-dictionary-based-approaches.html#cb98-5" tabindex="-1"></a><span class="fu">library</span>(quanteda) <span class="co"># tokenization power house</span></span>
<span id="cb98-6"><a href="week-3-dictionary-based-approaches.html#cb98-6" tabindex="-1"></a><span class="fu">library</span>(quanteda.textstats)</span>
<span id="cb98-7"><a href="week-3-dictionary-based-approaches.html#cb98-7" tabindex="-1"></a><span class="fu">library</span>(quanteda.dictionaries)</span>
<span id="cb98-8"><a href="week-3-dictionary-based-approaches.html#cb98-8" tabindex="-1"></a><span class="fu">library</span>(wesanderson) <span class="co"># to prettify</span></span>
<span id="cb98-9"><a href="week-3-dictionary-based-approaches.html#cb98-9" tabindex="-1"></a><span class="fu">library</span>(knitr) <span class="co"># for displaying data in html format (relevant for formatting this worksheet mainly)</span></span></code></pre></div>
</div>
<div id="get-data-2" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Get Data:</h2>
<p>For this example, we will be using data from <em>Ventura et al. (2021) - Connective effervescence and streaming chat during political debates</em>.</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="week-3-dictionary-based-approaches.html#cb99-1" tabindex="-1"></a><span class="fu">load</span>(<span class="st">&quot;data/ventura_etal_df.Rdata&quot;</span>)</span>
<span id="cb99-2"><a href="week-3-dictionary-based-approaches.html#cb99-2" tabindex="-1"></a><span class="fu">head</span>(ventura_etal_df)</span></code></pre></div>
<pre><code>##   text_id
## 1       1
## 2       2
## 3       3
## 4       4
## 5       5
## 6       6
##                                                                                                                                                                                                                                       comments
## 1 MORE:\n The coronavirus pandemic&#39;s impact on the race will be on display as the\n two candidates won&#39;t partake in a handshake, customary at the top of \nsuch events. The size of the audience will also be limited. https://abcn.ws/3kVyl16
## 2                                                                                                                                                           God please bless all Trump supporters. They need it for they know not what they do
## 3                                                                                                                               Trump  is  a  living  disaster!    What  an embarrassment  to  all  human  beings!    The  man  is  dangerous!
## 4                                                                                                                                                   This debate is why other counties laugh at us. School yard class president debate at best.
## 5                                                                    OMG\n ... shut up tRump ... so rude and out of control.  Obviously freaking \nout.  This is a debate NOT a convention or a speech or your platform.  \nLearn some manners
## 6                                                                                                      It’s\n hard to see what this country has become.  The Presidency is no longer a\n respected position it has lost all of it’s integrity.
##                      id likes                  debate
## 1              ABC News   100 abc_first_debate_manual
## 2            Anita Hill    61 abc_first_debate_manual
## 3          Dave Garland    99 abc_first_debate_manual
## 4              Carl Roy    47 abc_first_debate_manual
## 5 Lynda Martin-Chambers   154 abc_first_debate_manual
## 6         Nica Merchant   171 abc_first_debate_manual</code></pre>
</div>
<div id="tokenization-etc." class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Tokenization etc.</h2>
<p>The comments are mostly clean, but you can check (on your own) if they require more cleaning. In the previous code, I showed you how to lower, remove stopwords, etc., using quanteda. We can also do this using tidytext <a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>:</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="week-3-dictionary-based-approaches.html#cb101-1" tabindex="-1"></a>tidy_ventura <span class="ot">&lt;-</span> ventura_etal_df <span class="sc">%&gt;%</span> </span>
<span id="cb101-2"><a href="week-3-dictionary-based-approaches.html#cb101-2" tabindex="-1"></a>  <span class="co"># to lower:</span></span>
<span id="cb101-3"><a href="week-3-dictionary-based-approaches.html#cb101-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">comments =</span> <span class="fu">tolower</span>(comments)) <span class="sc">%&gt;%</span></span>
<span id="cb101-4"><a href="week-3-dictionary-based-approaches.html#cb101-4" tabindex="-1"></a>  <span class="co"># tokenize</span></span>
<span id="cb101-5"><a href="week-3-dictionary-based-approaches.html#cb101-5" tabindex="-1"></a>  <span class="fu">unnest_tokens</span>(word, comments) <span class="sc">%&gt;%</span></span>
<span id="cb101-6"><a href="week-3-dictionary-based-approaches.html#cb101-6" tabindex="-1"></a>  <span class="co"># keep only words (check regex)</span></span>
<span id="cb101-7"><a href="week-3-dictionary-based-approaches.html#cb101-7" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">str_detect</span>(word, <span class="st">&quot;[a-z]&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb101-8"><a href="week-3-dictionary-based-approaches.html#cb101-8" tabindex="-1"></a>  <span class="co"># remove stop words</span></span>
<span id="cb101-9"><a href="week-3-dictionary-based-approaches.html#cb101-9" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="sc">!</span>word <span class="sc">%in%</span> stop_words<span class="sc">$</span>word)</span></code></pre></div>
<pre><code>## mutate: changed 29,261 values (99%) of &#39;comments&#39; (0 new NA)</code></pre>
<pre><code>## filter: removed 3,374 rows (1%), 494,341 rows remaining</code></pre>
<pre><code>## filter: removed 296,793 rows (60%), 197,548 rows remaining</code></pre>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="week-3-dictionary-based-approaches.html#cb105-1" tabindex="-1"></a><span class="fu">head</span>(tidy_ventura, <span class="dv">20</span>)</span></code></pre></div>
<pre><code>##    text_id         id likes                  debate        word
## 1        1   ABC News   100 abc_first_debate_manual coronavirus
## 2        1   ABC News   100 abc_first_debate_manual  pandemic&#39;s
## 3        1   ABC News   100 abc_first_debate_manual      impact
## 4        1   ABC News   100 abc_first_debate_manual        race
## 5        1   ABC News   100 abc_first_debate_manual     display
## 6        1   ABC News   100 abc_first_debate_manual  candidates
## 7        1   ABC News   100 abc_first_debate_manual     partake
## 8        1   ABC News   100 abc_first_debate_manual   handshake
## 9        1   ABC News   100 abc_first_debate_manual   customary
## 10       1   ABC News   100 abc_first_debate_manual         top
## 11       1   ABC News   100 abc_first_debate_manual      events
## 12       1   ABC News   100 abc_first_debate_manual        size
## 13       1   ABC News   100 abc_first_debate_manual    audience
## 14       1   ABC News   100 abc_first_debate_manual     limited
## 15       1   ABC News   100 abc_first_debate_manual       https
## 16       1   ABC News   100 abc_first_debate_manual     abcn.ws
## 17       1   ABC News   100 abc_first_debate_manual     3kvyl16
## 18       2 Anita Hill    61 abc_first_debate_manual         god
## 19       2 Anita Hill    61 abc_first_debate_manual       bless
## 20       2 Anita Hill    61 abc_first_debate_manual       trump</code></pre>
</div>
<div id="keywords" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> Keywords</h2>
<p>We can detect the occurrence of the words <strong>trump</strong> and <strong>biden</strong> in each comment (<code>text_id</code>).</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="week-3-dictionary-based-approaches.html#cb107-1" tabindex="-1"></a>trump_biden <span class="ot">&lt;-</span> tidy_ventura <span class="sc">%&gt;%</span></span>
<span id="cb107-2"><a href="week-3-dictionary-based-approaches.html#cb107-2" tabindex="-1"></a>  <span class="co"># create a dummy</span></span>
<span id="cb107-3"><a href="week-3-dictionary-based-approaches.html#cb107-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">trump_token =</span> <span class="fu">ifelse</span>(word<span class="sc">==</span><span class="st">&quot;trump&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb107-4"><a href="week-3-dictionary-based-approaches.html#cb107-4" tabindex="-1"></a>         <span class="at">biden_token =</span> <span class="fu">ifelse</span>(word<span class="sc">==</span><span class="st">&quot;biden&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb107-5"><a href="week-3-dictionary-based-approaches.html#cb107-5" tabindex="-1"></a>  <span class="co"># see which comments have the word trump / biden</span></span>
<span id="cb107-6"><a href="week-3-dictionary-based-approaches.html#cb107-6" tabindex="-1"></a>  <span class="fu">group_by</span>(text_id) <span class="sc">%&gt;%</span></span>
<span id="cb107-7"><a href="week-3-dictionary-based-approaches.html#cb107-7" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">trump_cmmnt =</span> <span class="fu">ifelse</span>(<span class="fu">sum</span>(trump_token)<span class="sc">&gt;</span><span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb107-8"><a href="week-3-dictionary-based-approaches.html#cb107-8" tabindex="-1"></a>         <span class="at">biden_cmmnt =</span> <span class="fu">ifelse</span>(<span class="fu">sum</span>(biden_token)<span class="sc">&gt;</span><span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb107-9"><a href="week-3-dictionary-based-approaches.html#cb107-9" tabindex="-1"></a>  <span class="co"># reduce to our unit of analysis (comment) </span></span>
<span id="cb107-10"><a href="week-3-dictionary-based-approaches.html#cb107-10" tabindex="-1"></a>  <span class="fu">distinct</span>(text_id, <span class="at">.keep_all =</span> T) <span class="sc">%&gt;%</span></span>
<span id="cb107-11"><a href="week-3-dictionary-based-approaches.html#cb107-11" tabindex="-1"></a>  <span class="fu">select</span>(text_id,trump_cmmnt,biden_cmmnt,likes,debate)</span></code></pre></div>
<pre><code>## mutate: new variable &#39;trump_token&#39; (double) with 2 unique values and 0% NA</code></pre>
<pre><code>##         new variable &#39;biden_token&#39; (double) with 2 unique values and 0% NA</code></pre>
<pre><code>## group_by: one grouping variable (text_id)</code></pre>
<pre><code>## mutate (grouped): new variable &#39;trump_cmmnt&#39; (double) with 2 unique values and 0% NA</code></pre>
<pre><code>##                   new variable &#39;biden_cmmnt&#39; (double) with 2 unique values and 0% NA</code></pre>
<pre><code>## distinct (grouped): removed 168,013 rows (85%), 29,535 rows remaining</code></pre>
<pre><code>## select: dropped 4 variables (id, word, trump_token, biden_token)</code></pre>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="week-3-dictionary-based-approaches.html#cb115-1" tabindex="-1"></a><span class="fu">head</span>(trump_biden, <span class="dv">20</span>)</span></code></pre></div>
<pre><code>## # A tibble: 20 × 5
## # Groups:   text_id [20]
##    text_id trump_cmmnt biden_cmmnt likes debate                 
##      &lt;int&gt;       &lt;dbl&gt;       &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;                  
##  1       1           0           0   100 abc_first_debate_manual
##  2       2           1           0    61 abc_first_debate_manual
##  3       3           1           0    99 abc_first_debate_manual
##  4       4           0           0    47 abc_first_debate_manual
##  5       5           1           0   154 abc_first_debate_manual
##  6       6           0           0   171 abc_first_debate_manual
##  7       7           0           0    79 abc_first_debate_manual
##  8       8           0           0    39 abc_first_debate_manual
##  9       9           0           0    53 abc_first_debate_manual
## 10      10           0           0    36 abc_first_debate_manual
## 11      11           1           0    41 abc_first_debate_manual
## 12      12           0           0    28 abc_first_debate_manual
## 13      13           1           0    54 abc_first_debate_manual
## 14      14           0           0    30 abc_first_debate_manual
## 15      15           1           0    27 abc_first_debate_manual
## 16      16           1           1    31 abc_first_debate_manual
## 17      17           1           0    35 abc_first_debate_manual
## 18      18           1           1    32 abc_first_debate_manual
## 19      19           0           0    34 abc_first_debate_manual
## 20      20           1           0    37 abc_first_debate_manual</code></pre>
<p>Rather than replicating the results from Figure 3 in Ventura et al. (2021), we will estimate the median number of likes a comment mentioning Trump, Biden, Both, and None get:</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="week-3-dictionary-based-approaches.html#cb117-1" tabindex="-1"></a>trump_biden <span class="sc">%&gt;%</span></span>
<span id="cb117-2"><a href="week-3-dictionary-based-approaches.html#cb117-2" tabindex="-1"></a>  <span class="co"># Create categories</span></span>
<span id="cb117-3"><a href="week-3-dictionary-based-approaches.html#cb117-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">mentions_cat =</span> <span class="fu">ifelse</span>(trump_cmmnt<span class="sc">==</span><span class="dv">0</span> <span class="sc">&amp;</span> biden_cmmnt<span class="sc">==</span><span class="dv">0</span>, <span class="st">&quot;1. None&quot;</span>, <span class="cn">NA</span>),</span>
<span id="cb117-4"><a href="week-3-dictionary-based-approaches.html#cb117-4" tabindex="-1"></a>         <span class="at">mentions_cat =</span> <span class="fu">ifelse</span>(trump_cmmnt<span class="sc">==</span><span class="dv">1</span> <span class="sc">&amp;</span> biden_cmmnt<span class="sc">==</span><span class="dv">0</span>, <span class="st">&quot;2. Trump&quot;</span>, mentions_cat),</span>
<span id="cb117-5"><a href="week-3-dictionary-based-approaches.html#cb117-5" tabindex="-1"></a>         <span class="at">mentions_cat =</span> <span class="fu">ifelse</span>(trump_cmmnt<span class="sc">==</span><span class="dv">0</span> <span class="sc">&amp;</span> biden_cmmnt<span class="sc">==</span><span class="dv">1</span>, <span class="st">&quot;3. Biden&quot;</span>, mentions_cat),</span>
<span id="cb117-6"><a href="week-3-dictionary-based-approaches.html#cb117-6" tabindex="-1"></a>         <span class="at">mentions_cat =</span> <span class="fu">ifelse</span>(trump_cmmnt<span class="sc">==</span><span class="dv">1</span> <span class="sc">&amp;</span> biden_cmmnt<span class="sc">==</span><span class="dv">1</span>, <span class="st">&quot;4. Both&quot;</span>, mentions_cat)) <span class="sc">%&gt;%</span></span>
<span id="cb117-7"><a href="week-3-dictionary-based-approaches.html#cb117-7" tabindex="-1"></a>  <span class="fu">group_by</span>(mentions_cat) <span class="sc">%&gt;%</span></span>
<span id="cb117-8"><a href="week-3-dictionary-based-approaches.html#cb117-8" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">likes_mean =</span> <span class="fu">median</span>(likes, <span class="at">na.rm =</span> T)) <span class="sc">%&gt;%</span></span>
<span id="cb117-9"><a href="week-3-dictionary-based-approaches.html#cb117-9" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb117-10"><a href="week-3-dictionary-based-approaches.html#cb117-10" tabindex="-1"></a>  <span class="co"># Remove the ones people like too much</span></span>
<span id="cb117-11"><a href="week-3-dictionary-based-approaches.html#cb117-11" tabindex="-1"></a>  <span class="fu">filter</span>(likes <span class="sc">&lt;</span> <span class="dv">26</span>) <span class="sc">%&gt;%</span></span>
<span id="cb117-12"><a href="week-3-dictionary-based-approaches.html#cb117-12" tabindex="-1"></a>  <span class="co"># Plot</span></span>
<span id="cb117-13"><a href="week-3-dictionary-based-approaches.html#cb117-13" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>likes,<span class="at">fill =</span> mentions_cat, <span class="at">color =</span> mentions_cat)) <span class="sc">+</span></span>
<span id="cb117-14"><a href="week-3-dictionary-based-approaches.html#cb117-14" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">alpha =</span> <span class="fl">0.3</span>) <span class="sc">+</span></span>
<span id="cb117-15"><a href="week-3-dictionary-based-approaches.html#cb117-15" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">wes_palette</span>(<span class="st">&quot;BottleRocket2&quot;</span>)) <span class="sc">+</span></span>
<span id="cb117-16"><a href="week-3-dictionary-based-approaches.html#cb117-16" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">wes_palette</span>(<span class="st">&quot;BottleRocket2&quot;</span>)) <span class="sc">+</span></span>
<span id="cb117-17"><a href="week-3-dictionary-based-approaches.html#cb117-17" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>mentions_cat, <span class="at">ncol =</span> <span class="dv">1</span>) <span class="sc">+</span> </span>
<span id="cb117-18"><a href="week-3-dictionary-based-approaches.html#cb117-18" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb117-19"><a href="week-3-dictionary-based-approaches.html#cb117-19" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> likes_mean, <span class="at">color =</span> mentions_cat), <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>)<span class="sc">+</span></span>
<span id="cb117-20"><a href="week-3-dictionary-based-approaches.html#cb117-20" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position=</span><span class="st">&quot;none&quot;</span>) <span class="sc">+</span></span>
<span id="cb117-21"><a href="week-3-dictionary-based-approaches.html#cb117-21" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>, <span class="at">color =</span> <span class="st">&quot;&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb117-22"><a href="week-3-dictionary-based-approaches.html#cb117-22" tabindex="-1"></a>       <span class="at">caption =</span> <span class="st">&quot;Note: Median likes in dashed lines.&quot;</span>)</span></code></pre></div>
<pre><code>## mutate (grouped): new variable &#39;mentions_cat&#39; (character) with 4 unique values and 0% NA</code></pre>
<pre><code>## group_by: one grouping variable (mentions_cat)</code></pre>
<pre><code>## mutate (grouped): new variable &#39;likes_mean&#39; (double) with 4 unique values and 0% NA</code></pre>
<pre><code>## ungroup: no grouping variables</code></pre>
<pre><code>## filter: removed 8,136 rows (28%), 21,399 rows remaining</code></pre>
<p><img src="main_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<p>And we can also see if there are differences across news media:</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="week-3-dictionary-based-approaches.html#cb123-1" tabindex="-1"></a>trump_biden <span class="sc">%&gt;%</span></span>
<span id="cb123-2"><a href="week-3-dictionary-based-approaches.html#cb123-2" tabindex="-1"></a>  <span class="co"># Create categories</span></span>
<span id="cb123-3"><a href="week-3-dictionary-based-approaches.html#cb123-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">mentions_cat =</span> <span class="fu">ifelse</span>(trump_cmmnt<span class="sc">==</span><span class="dv">0</span> <span class="sc">&amp;</span> biden_cmmnt<span class="sc">==</span><span class="dv">0</span>, <span class="st">&quot;1. None&quot;</span>, <span class="cn">NA</span>),</span>
<span id="cb123-4"><a href="week-3-dictionary-based-approaches.html#cb123-4" tabindex="-1"></a>         <span class="at">mentions_cat =</span> <span class="fu">ifelse</span>(trump_cmmnt<span class="sc">==</span><span class="dv">1</span> <span class="sc">&amp;</span> biden_cmmnt<span class="sc">==</span><span class="dv">0</span>, <span class="st">&quot;2. Trump&quot;</span>, mentions_cat),</span>
<span id="cb123-5"><a href="week-3-dictionary-based-approaches.html#cb123-5" tabindex="-1"></a>         <span class="at">mentions_cat =</span> <span class="fu">ifelse</span>(trump_cmmnt<span class="sc">==</span><span class="dv">0</span> <span class="sc">&amp;</span> biden_cmmnt<span class="sc">==</span><span class="dv">1</span>, <span class="st">&quot;3. Biden&quot;</span>, mentions_cat),</span>
<span id="cb123-6"><a href="week-3-dictionary-based-approaches.html#cb123-6" tabindex="-1"></a>         <span class="at">mentions_cat =</span> <span class="fu">ifelse</span>(trump_cmmnt<span class="sc">==</span><span class="dv">1</span> <span class="sc">&amp;</span> biden_cmmnt<span class="sc">==</span><span class="dv">1</span>, <span class="st">&quot;4. Both&quot;</span>, mentions_cat),</span>
<span id="cb123-7"><a href="week-3-dictionary-based-approaches.html#cb123-7" tabindex="-1"></a>         <span class="at">media =</span> <span class="fu">ifelse</span>(<span class="fu">str_detect</span>(debate, <span class="st">&quot;abc&quot;</span>), <span class="st">&quot;ABC&quot;</span>, <span class="cn">NA</span>),</span>
<span id="cb123-8"><a href="week-3-dictionary-based-approaches.html#cb123-8" tabindex="-1"></a>         <span class="at">media =</span> <span class="fu">ifelse</span>(<span class="fu">str_detect</span>(debate, <span class="st">&quot;nbc&quot;</span>), <span class="st">&quot;NBC&quot;</span>, media),</span>
<span id="cb123-9"><a href="week-3-dictionary-based-approaches.html#cb123-9" tabindex="-1"></a>         <span class="at">media =</span> <span class="fu">ifelse</span>(<span class="fu">str_detect</span>(debate, <span class="st">&quot;fox&quot;</span>), <span class="st">&quot;FOX&quot;</span>, media)) <span class="sc">%&gt;%</span></span>
<span id="cb123-10"><a href="week-3-dictionary-based-approaches.html#cb123-10" tabindex="-1"></a>  <span class="fu">group_by</span>(mentions_cat,media) <span class="sc">%&gt;%</span></span>
<span id="cb123-11"><a href="week-3-dictionary-based-approaches.html#cb123-11" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">median_like =</span> <span class="fu">median</span>(likes,<span class="at">na.rm =</span> T)) <span class="sc">%&gt;%</span></span>
<span id="cb123-12"><a href="week-3-dictionary-based-approaches.html#cb123-12" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb123-13"><a href="week-3-dictionary-based-approaches.html#cb123-13" tabindex="-1"></a>  <span class="co"># Remove the ones people like too much</span></span>
<span id="cb123-14"><a href="week-3-dictionary-based-approaches.html#cb123-14" tabindex="-1"></a>  <span class="fu">filter</span>(likes <span class="sc">&lt;</span> <span class="dv">26</span>) <span class="sc">%&gt;%</span></span>
<span id="cb123-15"><a href="week-3-dictionary-based-approaches.html#cb123-15" tabindex="-1"></a>  <span class="co"># Plot</span></span>
<span id="cb123-16"><a href="week-3-dictionary-based-approaches.html#cb123-16" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>likes,<span class="at">fill =</span> mentions_cat, <span class="at">color =</span> mentions_cat)) <span class="sc">+</span></span>
<span id="cb123-17"><a href="week-3-dictionary-based-approaches.html#cb123-17" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">alpha =</span> <span class="fl">0.3</span>) <span class="sc">+</span></span>
<span id="cb123-18"><a href="week-3-dictionary-based-approaches.html#cb123-18" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">wes_palette</span>(<span class="st">&quot;BottleRocket2&quot;</span>)) <span class="sc">+</span></span>
<span id="cb123-19"><a href="week-3-dictionary-based-approaches.html#cb123-19" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">wes_palette</span>(<span class="st">&quot;BottleRocket2&quot;</span>)) <span class="sc">+</span></span>
<span id="cb123-20"><a href="week-3-dictionary-based-approaches.html#cb123-20" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>media, <span class="at">ncol =</span> <span class="dv">1</span>) <span class="sc">+</span> </span>
<span id="cb123-21"><a href="week-3-dictionary-based-approaches.html#cb123-21" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> median_like, <span class="at">color =</span> mentions_cat), <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>)<span class="sc">+</span></span>
<span id="cb123-22"><a href="week-3-dictionary-based-approaches.html#cb123-22" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb123-23"><a href="week-3-dictionary-based-approaches.html#cb123-23" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position=</span><span class="st">&quot;bottom&quot;</span>) <span class="sc">+</span></span>
<span id="cb123-24"><a href="week-3-dictionary-based-approaches.html#cb123-24" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>, <span class="at">color =</span> <span class="st">&quot;&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb123-25"><a href="week-3-dictionary-based-approaches.html#cb123-25" tabindex="-1"></a>       <span class="at">caption =</span> <span class="st">&quot;Note: Median likes in dashed lines.&quot;</span>)</span></code></pre></div>
<pre><code>## mutate (grouped): new variable &#39;mentions_cat&#39; (character) with 4 unique values and 0% NA</code></pre>
<pre><code>##                   new variable &#39;media&#39; (character) with 3 unique values and 0% NA</code></pre>
<pre><code>## group_by: 2 grouping variables (mentions_cat, media)</code></pre>
<pre><code>## mutate (grouped): new variable &#39;median_like&#39; (double) with 6 unique values and 0% NA</code></pre>
<pre><code>## ungroup: no grouping variables</code></pre>
<pre><code>## filter: removed 8,136 rows (28%), 21,399 rows remaining</code></pre>
<p><img src="main_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<p>Similar to Young and Soroka (2012), we can also explore our keywords of interest in context. This is a good way to validate our proposed measure (e.g., Is mentioning <em>trump</em> a reflection of interest? Of relevance?).</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="week-3-dictionary-based-approaches.html#cb130-1" tabindex="-1"></a>corpus_ventura <span class="ot">&lt;-</span> <span class="fu">corpus</span>(ventura_etal_df,</span>
<span id="cb130-2"><a href="week-3-dictionary-based-approaches.html#cb130-2" tabindex="-1"></a>                     <span class="at">text_field =</span> <span class="st">&quot;comments&quot;</span>,</span>
<span id="cb130-3"><a href="week-3-dictionary-based-approaches.html#cb130-3" tabindex="-1"></a>                     <span class="at">unique_docnames =</span> <span class="cn">TRUE</span>)</span>
<span id="cb130-4"><a href="week-3-dictionary-based-approaches.html#cb130-4" tabindex="-1"></a></span>
<span id="cb130-5"><a href="week-3-dictionary-based-approaches.html#cb130-5" tabindex="-1"></a>toks_ventura <span class="ot">&lt;-</span> <span class="fu">tokens</span>(corpus_ventura)</span>
<span id="cb130-6"><a href="week-3-dictionary-based-approaches.html#cb130-6" tabindex="-1"></a>kw_trump <span class="ot">&lt;-</span> <span class="fu">kwic</span>(toks_ventura, <span class="at">pattern =</span> <span class="st">&quot;Trump&quot;</span>)</span>
<span id="cb130-7"><a href="week-3-dictionary-based-approaches.html#cb130-7" tabindex="-1"></a></span>
<span id="cb130-8"><a href="week-3-dictionary-based-approaches.html#cb130-8" tabindex="-1"></a><span class="do">## The number determines the size of the window: how many tokens before and after</span></span>
<span id="cb130-9"><a href="week-3-dictionary-based-approaches.html#cb130-9" tabindex="-1"></a><span class="fu">head</span>(kw_trump, <span class="dv">20</span>)</span></code></pre></div>
<pre><code>## Keyword-in-context with 20 matches.                                                 
##    [text2, 5]      God please bless all | Trump |
##    [text3, 1]                           | Trump |
##    [text5, 7]               ... shut up | tRump |
##  [text11, 11] a bad opiate problem then | trump |
##   [text13, 4]                 This is a | TRUMP |
##   [text15, 1]                           | Trump |
##   [text16, 8]  this SO much better than | Trump |
##   [text17, 3]                    I love | Trump |
##   [text18, 4]            Biden is right | Trump |
##   [text20, 1]                           | Trump |
##  [text22, 12]     being a decent human. | Trump |
##   [text23, 1]                           | Trump |
##  [text27, 11]          for once, i wish | trump |
##  [text28, 10]             it America... | Trump |
##   [text30, 1]                           | Trump |
##   [text31, 1]                           | Trump |
##   [text32, 1]                           | Trump |
##  [text32, 15]    People open your eyes. | Trump |
##   [text34, 1]                           | Trump |
##   [text36, 1]                           | Trump |
##                                 
##  supporters. They need it       
##  is a living disaster!          
##  ... so rude                    
##  brings up about bidens son     
##  all about ME debate and        
##  is looking pretty flushed right
##  and I wasn’t even going        
##  ! He is the best               
##  doesn’t have a plan for        
##  worse president EVER 😡 thank  
##  doesn&#39;t know the meaning of    
##  such a hateful person he       
##  would shut his trap for        
##  IS NOT smarter than a          
##  has improved our economy and   
##  has done so much harm          
##  is a clown and after           
##  is evil.                       
##  is so broke that is            
##  is literally making this debate</code></pre>
<p>We can also look for more than one word at the same time:</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="week-3-dictionary-based-approaches.html#cb132-1" tabindex="-1"></a>kw_best <span class="ot">&lt;-</span> <span class="fu">kwic</span>(toks_ventura, <span class="at">pattern =</span> <span class="fu">c</span>(<span class="st">&quot;best&quot;</span>,<span class="st">&quot;worst&quot;</span>))</span>
<span id="cb132-2"><a href="week-3-dictionary-based-approaches.html#cb132-2" tabindex="-1"></a><span class="fu">head</span>(kw_best, <span class="dv">20</span>)</span></code></pre></div>
<pre><code>## Keyword-in-context with 20 matches.                                                       
##    [text4, 17] yard class president debate at | best  |
##    [text10, 1]                                | Worst |
##    [text17, 8]               Trump! He is the | best  |
##    [text43, 6]           This is gonna be the | best  |
##   [text81, 31]  an incompetent President, the | worst |
##   [text81, 33]          President, the worst, | worst |
##   [text81, 35]              the worst, worst, | worst |
##   [text82, 11]         was totally one sided! | Worst |
##    [text86, 8]           right - Trump is the | worst |
##   [text100, 9]             !! BRAVO BRAVO THE | BEST  |
##   [text102, 4]                  Obama was the | worst |
##  [text119, 10]            he said he would do | Best  |
##  [text138, 13]               think. He is the | worst |
##  [text141, 22]           puppet could be? The | worst |
##   [text143, 6]           Trump may not be the | best  |
##  [text158, 15]              This man is a the | worst |
##   [text167, 3]                         He the | worst |
##  [text221, 34]           by far have been the | worst |
##  [text221, 36]           have been the worst, | WORST |
##  [text221, 38]              the worst, WORST, | WORST |
##                                     
##  .                                  
##  debate I’ve ever seen!             
##  president ever! Thank you          
##  show on TV in 4                    
##  , worst, worst in                  
##  , worst in history.                
##  in history.                        
##  ever! Our president kept           
##  president America ever had!        
##  PRESIDENT OF THE WORLD.            
##  president ever!!!                  
##  President ever Crybabies don&#39;t like
##  president ever                     
##  president in our time ever         
##  choice but I will choose           
##  thing that has ever happened       
##  president we had in the            
##  , WORST, WORST PRESIDENT           
##  , WORST PRESIDENT!!                
##  PRESIDENT!!!</code></pre>
<p>Alternatively, we can see what are the most common words that happen together. These are called collocations (which is a similar concept to n-grams). We want to see the most common names mentioned (first and last name).</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="week-3-dictionary-based-approaches.html#cb134-1" tabindex="-1"></a>toks_ventura <span class="ot">&lt;-</span> <span class="fu">tokens</span>(corpus_ventura, <span class="at">remove_punct =</span> <span class="cn">TRUE</span>)</span>
<span id="cb134-2"><a href="week-3-dictionary-based-approaches.html#cb134-2" tabindex="-1"></a>col_ventura <span class="ot">&lt;-</span> <span class="fu">tokens_select</span>(toks_ventura, </span>
<span id="cb134-3"><a href="week-3-dictionary-based-approaches.html#cb134-3" tabindex="-1"></a>                                <span class="co"># Keep only tokens that start with a capital letter</span></span>
<span id="cb134-4"><a href="week-3-dictionary-based-approaches.html#cb134-4" tabindex="-1"></a>                                <span class="at">pattern =</span> <span class="st">&quot;^[A-Z]&quot;</span>, </span>
<span id="cb134-5"><a href="week-3-dictionary-based-approaches.html#cb134-5" tabindex="-1"></a>                                <span class="at">valuetype =</span> <span class="st">&quot;regex&quot;</span>, </span>
<span id="cb134-6"><a href="week-3-dictionary-based-approaches.html#cb134-6" tabindex="-1"></a>                                <span class="at">case_insensitive =</span> <span class="cn">FALSE</span>, </span>
<span id="cb134-7"><a href="week-3-dictionary-based-approaches.html#cb134-7" tabindex="-1"></a>                                <span class="at">padding =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb134-8"><a href="week-3-dictionary-based-approaches.html#cb134-8" tabindex="-1"></a>                  <span class="fu">textstat_collocations</span>(<span class="at">min_count =</span> <span class="dv">20</span>) <span class="co"># Minimum number of collocations to be taken into account.</span></span>
<span id="cb134-9"><a href="week-3-dictionary-based-approaches.html#cb134-9" tabindex="-1"></a><span class="fu">head</span>(col_ventura, <span class="dv">20</span>)</span></code></pre></div>
<pre><code>##          collocation count count_nested length    lambda         z
## 1      chris wallace  1693            0      2  6.753757 128.18781
## 2    president trump   831            0      2  3.752001  84.18127
## 3          joe biden   430            0      2  3.387851  59.35890
## 4           fox news   267            0      2  8.946604  53.79136
## 5       mr president   152            0      2  4.991810  45.90814
## 6      united states   144            0      2 12.106625  36.13436
## 7       donald trump   141            0      2  4.737341  35.49434
## 8         mike pence    40            0      2  8.952702  34.74382
## 9       jo jorgensen    78            0      2 10.969527  34.45630
## 10             HE IS    43            0      2  6.211846  34.14875
## 11    vice president   343            0      2  8.415032  33.26922
## 12  democratic party    38            0      2  9.093730  31.88339
## 13     CHRIS WALLACE    38            0      2  9.634206  31.78885
## 14   PRESIDENT TRUMP    37            0      2  5.852576  30.58102
## 15          TRUMP IS    42            0      2  5.197507  30.15495
## 16       white house    46            0      2 11.318748  29.41979
## 17 african americans    35            0      2  7.749976  29.38678
## 18         JOE BIDEN    25            0      2  7.541467  28.86445
## 19           YOU ARE    27            0      2  6.656140  28.82971
## 20            IS NOT    34            0      2  5.512521  28.74916</code></pre>
<p>(The <span class="math inline">\(\lambda\)</span> score is something like the likelihood of, for example, <em>chris</em> and <em>wallace</em> happening one next to the other. For a complete explanation, you can <a href="http://web.science.mq.edu.au/~mjohnson/papers/2001/dpb-colloc01.pdf">read this paper</a>.)</p>
<p>We can also discover collocations longer than two words. In the example below we identify collocations consisting of three words.</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="week-3-dictionary-based-approaches.html#cb136-1" tabindex="-1"></a>col_ventura <span class="ot">&lt;-</span> <span class="fu">tokens_select</span>(toks_ventura, </span>
<span id="cb136-2"><a href="week-3-dictionary-based-approaches.html#cb136-2" tabindex="-1"></a>                                <span class="at">case_insensitive =</span> <span class="cn">FALSE</span>, </span>
<span id="cb136-3"><a href="week-3-dictionary-based-approaches.html#cb136-3" tabindex="-1"></a>                                <span class="at">padding =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb136-4"><a href="week-3-dictionary-based-approaches.html#cb136-4" tabindex="-1"></a>              <span class="fu">textstat_collocations</span>(<span class="at">min_count =</span> <span class="dv">100</span>, <span class="at">size =</span> <span class="dv">3</span>)</span>
<span id="cb136-5"><a href="week-3-dictionary-based-approaches.html#cb136-5" tabindex="-1"></a><span class="fu">head</span>(col_ventura, <span class="dv">20</span>)</span></code></pre></div>
<pre><code>##            collocation count count_nested length      lambda            z
## 1          know how to   115            0      3 3.098900337 11.327580933
## 2  the american people   220            0      3 2.601543689 10.158047857
## 3          this is the   158            0      3 1.393091382  9.012926334
## 4           to do with   108            0      3 4.011182538  7.217176889
## 5       this debate is   167            0      3 0.997383245  6.159091461
## 6             is not a   139            0      3 0.796582289  6.084664757
## 7     wallace needs to   172            0      3 1.634217570  4.628866454
## 8         is the worst   110            0      3 1.840591657  3.639602823
## 9         trump is the   153            0      3 0.283527984  2.554551024
## 10           is such a   107            0      3 0.776224121  2.541279959
## 11           is a joke   247            0      3 2.091736055  2.524522767
## 12      trump has done   105            0      3 0.646275113  2.285231341
## 13          trump is a   322            0      3 0.202976986  2.002649763
## 14         this is not   119            0      3 0.446372828  1.986517242
## 15      trump needs to   131            0      3 0.580848241  1.941689788
## 16         what a joke   141            0      3 2.379466544  1.672336835
## 17   the united states   132            0      3 0.738367705  1.431647428
## 18         going to be   122            0      3 1.914497779  1.348587450
## 19         is going to   210            0      3 0.101463083  0.603531369
## 20          biden is a   164            0      3 0.001198663  0.009724797</code></pre>
</div>
<div id="dictionary-approaches" class="section level2" number="3.5">
<h2><span class="header-section-number">3.5</span> Dictionary Approaches</h2>
<p>We can extend the previous analysis by using dictionaries. You can create you own, you can use previously validates dictionaries, or you can use previously validates dictionaries that are already included with <code>tidytext</code> or <code>quanteda</code> (for sentiment analysis).</p>
<div id="sentiment-analysis" class="section level3" number="3.5.1">
<h3><span class="header-section-number">3.5.1</span> Sentiment Analysis</h3>
<p>Let’s look at some pre-loaded sentiment dictionaries in <code>tidytext</code>:</p>
<ul>
<li><code>AFFIN</code>: measures sentiment with a numeric score between -5 and 5, and were validated in <a href="http://www2.imm.dtu.dk/pubdb/edoc/imm6006.pdf">this paper</a>.</li>
</ul>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="week-3-dictionary-based-approaches.html#cb138-1" tabindex="-1"></a><span class="fu">get_sentiments</span>(<span class="st">&quot;afinn&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 2,477 × 2
##    word       value
##    &lt;chr&gt;      &lt;dbl&gt;
##  1 abandon       -2
##  2 abandoned     -2
##  3 abandons      -2
##  4 abducted      -2
##  5 abduction     -2
##  6 abductions    -2
##  7 abhor         -3
##  8 abhorred      -3
##  9 abhorrent     -3
## 10 abhors        -3
## # ℹ 2,467 more rows</code></pre>
<ul>
<li><code>bing</code>: sentiment words found in online forums. More information <a href="https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html">here</a>.</li>
</ul>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="week-3-dictionary-based-approaches.html#cb140-1" tabindex="-1"></a><span class="fu">get_sentiments</span>(<span class="st">&quot;bing&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 6,786 × 2
##    word        sentiment
##    &lt;chr&gt;       &lt;chr&gt;    
##  1 2-faces     negative 
##  2 abnormal    negative 
##  3 abolish     negative 
##  4 abominable  negative 
##  5 abominably  negative 
##  6 abominate   negative 
##  7 abomination negative 
##  8 abort       negative 
##  9 aborted     negative 
## 10 aborts      negative 
## # ℹ 6,776 more rows</code></pre>
<ul>
<li><code>nrc</code>: underpaid workers from Amazon mechanical Turk coded the emotional valence of a long list of terms, which were validated in <a href="https://arxiv.org/pdf/1308.6297.pdf">this paper</a>.</li>
</ul>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="week-3-dictionary-based-approaches.html#cb142-1" tabindex="-1"></a><span class="fu">get_sentiments</span>(<span class="st">&quot;nrc&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 13,872 × 2
##    word        sentiment
##    &lt;chr&gt;       &lt;chr&gt;    
##  1 abacus      trust    
##  2 abandon     fear     
##  3 abandon     negative 
##  4 abandon     sadness  
##  5 abandoned   anger    
##  6 abandoned   fear     
##  7 abandoned   negative 
##  8 abandoned   sadness  
##  9 abandonment anger    
## 10 abandonment fear     
## # ℹ 13,862 more rows</code></pre>
<p>Each dictionary classifies and quantifies words in a different way. Let’s use the <code>nrc</code> sentiment dictionary to analyze our comments dataset. <code>nrc</code> classifies words as whether having <em>positive</em> or <em>negative</em> sentiment.</p>
<p>Each dictionary classifies and quantifies words in a different way. Let’s use the <code>nrc</code> sentiment dictionary to analyze our comments dataset. <code>nrc</code> classifies words as whether reflecting:</p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="week-3-dictionary-based-approaches.html#cb144-1" tabindex="-1"></a>nrc <span class="ot">&lt;-</span> <span class="fu">get_sentiments</span>(<span class="st">&quot;nrc&quot;</span>) </span>
<span id="cb144-2"><a href="week-3-dictionary-based-approaches.html#cb144-2" tabindex="-1"></a><span class="fu">table</span>(nrc<span class="sc">$</span>sentiment)</span></code></pre></div>
<pre><code>## 
##        anger anticipation      disgust         fear          joy     negative 
##         1245          837         1056         1474          687         3316 
##     positive      sadness     surprise        trust 
##         2308         1187          532         1230</code></pre>
<p>We will focus solely on <em>positive</em> or <em>negative</em> sentiment:</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="week-3-dictionary-based-approaches.html#cb146-1" tabindex="-1"></a>nrc_pos_neg <span class="ot">&lt;-</span> <span class="fu">get_sentiments</span>(<span class="st">&quot;nrc&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb146-2"><a href="week-3-dictionary-based-approaches.html#cb146-2" tabindex="-1"></a>  <span class="fu">filter</span>(sentiment <span class="sc">==</span> <span class="st">&quot;positive&quot;</span> <span class="sc">|</span> sentiment <span class="sc">==</span> <span class="st">&quot;negative&quot;</span>)</span></code></pre></div>
<pre><code>## filter: removed 8,248 rows (59%), 5,624 rows remaining</code></pre>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="week-3-dictionary-based-approaches.html#cb148-1" tabindex="-1"></a>ventura_pos_neg <span class="ot">&lt;-</span> tidy_ventura <span class="sc">%&gt;%</span></span>
<span id="cb148-2"><a href="week-3-dictionary-based-approaches.html#cb148-2" tabindex="-1"></a>  <span class="fu">left_join</span>(nrc_pos_neg)</span></code></pre></div>
<pre><code>## Joining with `by = join_by(word)`</code></pre>
<pre><code>## left_join: added one column (sentiment)</code></pre>
<pre><code>##            &gt; rows only in x   147,204</code></pre>
<pre><code>##            &gt; rows only in y  (  3,402)</code></pre>
<pre><code>##            &gt; matched rows      52,059    (includes duplicates)</code></pre>
<pre><code>##            &gt;                 =========</code></pre>
<pre><code>##            &gt; rows total       199,263</code></pre>
<p>Let’s check the top <em>positive</em> words and the top <em>negative</em> words:</p>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="week-3-dictionary-based-approaches.html#cb156-1" tabindex="-1"></a>ventura_pos_neg <span class="sc">%&gt;%</span></span>
<span id="cb156-2"><a href="week-3-dictionary-based-approaches.html#cb156-2" tabindex="-1"></a>  <span class="fu">group_by</span>(sentiment) <span class="sc">%&gt;%</span></span>
<span id="cb156-3"><a href="week-3-dictionary-based-approaches.html#cb156-3" tabindex="-1"></a>  <span class="fu">count</span>(word, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## group_by: one grouping variable (sentiment)</code></pre>
<pre><code>## count: now 14,242 rows and 3 columns, one group variable remaining (sentiment)</code></pre>
<pre><code>## # A tibble: 14,242 × 3
## # Groups:   sentiment [3]
##    sentiment word          n
##    &lt;chr&gt;     &lt;chr&gt;     &lt;int&gt;
##  1 &lt;NA&gt;      trump     11676
##  2 &lt;NA&gt;      biden      7847
##  3 positive  president  4920
##  4 &lt;NA&gt;      wallace    4188
##  5 positive  debate     2693
##  6 &lt;NA&gt;      people     2591
##  7 &lt;NA&gt;      chris      2559
##  8 &lt;NA&gt;      joe        2380
##  9 &lt;NA&gt;      country    1589
## 10 &lt;NA&gt;      time       1226
## # ℹ 14,232 more rows</code></pre>
<p>Some make sense: ‘love’ is <em>positive</em>, ‘bully’ is <em>negative</em>. Some, not so much: ‘talk’ is positive? ‘joke’ is negative? Some are out of context: A ‘vice’ is negative, but THE ‘vice’-president is not (especially since presidente is considered ‘positive’, which… really?). And then ‘vote’ is both positive and negative which… what? Let’s turn a blind eye for now (but, once again, go back to Grimmer et al. Ch. 15 for best practices).</p>
<p>Are people watching different news media using different language? Let’s see what the data tells us. As always, check the unit of analysis of your dataset. In this case, each observation is a word, but we have the grouping variable of the comment (<code>text_id</code>), so we can count how many <em>positive</em> and <em>negative</em> words per comment. We will calculate a net sentiment score by subtracting the number of negative words from positive word (in each comment).</p>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="week-3-dictionary-based-approaches.html#cb160-1" tabindex="-1"></a>comment_pos_neg <span class="ot">&lt;-</span> ventura_pos_neg <span class="sc">%&gt;%</span></span>
<span id="cb160-2"><a href="week-3-dictionary-based-approaches.html#cb160-2" tabindex="-1"></a>  <span class="co"># Create dummies of pos and neg for counting</span></span>
<span id="cb160-3"><a href="week-3-dictionary-based-approaches.html#cb160-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">pos_dum =</span> <span class="fu">ifelse</span>(sentiment <span class="sc">==</span> <span class="st">&quot;positive&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb160-4"><a href="week-3-dictionary-based-approaches.html#cb160-4" tabindex="-1"></a>         <span class="at">neg_dum =</span> <span class="fu">ifelse</span>(sentiment <span class="sc">==</span> <span class="st">&quot;negative&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb160-5"><a href="week-3-dictionary-based-approaches.html#cb160-5" tabindex="-1"></a>  <span class="co"># Estimate total number of tokens per comment, pos , and negs</span></span>
<span id="cb160-6"><a href="week-3-dictionary-based-approaches.html#cb160-6" tabindex="-1"></a>  <span class="fu">group_by</span>(text_id) <span class="sc">%&gt;%</span></span>
<span id="cb160-7"><a href="week-3-dictionary-based-approaches.html#cb160-7" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">total_words =</span> <span class="fu">n</span>(),</span>
<span id="cb160-8"><a href="week-3-dictionary-based-approaches.html#cb160-8" tabindex="-1"></a>         <span class="at">total_pos =</span> <span class="fu">sum</span>(pos_dum, <span class="at">na.rm =</span> T),</span>
<span id="cb160-9"><a href="week-3-dictionary-based-approaches.html#cb160-9" tabindex="-1"></a>         <span class="at">total_neg =</span> <span class="fu">sum</span>(neg_dum, <span class="at">na.rm =</span> T)) <span class="sc">%&gt;%</span></span>
<span id="cb160-10"><a href="week-3-dictionary-based-approaches.html#cb160-10" tabindex="-1"></a>  <span class="co"># These values are aggregated at the text_id level so we can eliminate repeated text_id</span></span>
<span id="cb160-11"><a href="week-3-dictionary-based-approaches.html#cb160-11" tabindex="-1"></a>  <span class="fu">distinct</span>(text_id,<span class="at">.keep_all=</span><span class="cn">TRUE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb160-12"><a href="week-3-dictionary-based-approaches.html#cb160-12" tabindex="-1"></a>  <span class="co"># Now we estimate the net sentiment score. You can change this and get a different way to measure the ratio of positive to negative</span></span>
<span id="cb160-13"><a href="week-3-dictionary-based-approaches.html#cb160-13" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">net_sent =</span> total_pos <span class="sc">-</span> total_neg) <span class="sc">%&gt;%</span></span>
<span id="cb160-14"><a href="week-3-dictionary-based-approaches.html#cb160-14" tabindex="-1"></a>  <span class="fu">ungroup</span>() </span></code></pre></div>
<pre><code>## mutate: new variable &#39;pos_dum&#39; (double) with 3 unique values and 74% NA</code></pre>
<pre><code>##         new variable &#39;neg_dum&#39; (double) with 3 unique values and 74% NA</code></pre>
<pre><code>## group_by: one grouping variable (text_id)</code></pre>
<pre><code>## mutate (grouped): new variable &#39;total_words&#39; (integer) with 25 unique values and 0% NA</code></pre>
<pre><code>##                   new variable &#39;total_pos&#39; (double) with 14 unique values and 0% NA</code></pre>
<pre><code>##                   new variable &#39;total_neg&#39; (double) with 10 unique values and 0% NA</code></pre>
<pre><code>## distinct (grouped): removed 169,728 rows (85%), 29,535 rows remaining</code></pre>
<pre><code>## mutate (grouped): new variable &#39;net_sent&#39; (double) with 21 unique values and 0% NA</code></pre>
<pre><code>## ungroup: no grouping variables</code></pre>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="week-3-dictionary-based-approaches.html#cb170-1" tabindex="-1"></a><span class="co"># Note that the `word` and `sentiment` columns are meaningless now</span></span>
<span id="cb170-2"><a href="week-3-dictionary-based-approaches.html#cb170-2" tabindex="-1"></a><span class="fu">head</span>(comment_pos_neg, <span class="dv">10</span>)</span></code></pre></div>
<pre><code>## # A tibble: 10 × 12
##    text_id id           likes debate word  sentiment pos_dum neg_dum total_words
##      &lt;int&gt; &lt;chr&gt;        &lt;int&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;       &lt;int&gt;
##  1       1 ABC News       100 abc_f… coro… &lt;NA&gt;           NA      NA          17
##  2       2 Anita Hill      61 abc_f… god   positive        1       0           4
##  3       3 Dave Garland    99 abc_f… trump &lt;NA&gt;           NA      NA           6
##  4       4 Carl Roy        47 abc_f… deba… positive        1       0           8
##  5       5 Lynda Marti…   154 abc_f… omg   &lt;NA&gt;           NA      NA          12
##  6       6 Nica Mercha…   171 abc_f… it’s  &lt;NA&gt;           NA      NA           9
##  7       7 Connie Sage     79 abc_f… happ… &lt;NA&gt;           NA      NA           7
##  8       8 Tammy Eisen     39 abc_f… expe… &lt;NA&gt;           NA      NA           4
##  9       9 Susan Weyant    53 abc_f… smart &lt;NA&gt;           NA      NA          13
## 10      10 Dana Spencer    36 abc_f… worst &lt;NA&gt;           NA      NA          15
## # ℹ 3 more variables: total_pos &lt;dbl&gt;, total_neg &lt;dbl&gt;, net_sent &lt;dbl&gt;</code></pre>
<p>Ok, now we can plot the differences:</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="week-3-dictionary-based-approaches.html#cb172-1" tabindex="-1"></a>comment_pos_neg <span class="sc">%&gt;%</span></span>
<span id="cb172-2"><a href="week-3-dictionary-based-approaches.html#cb172-2" tabindex="-1"></a>    <span class="co"># Create categories</span></span>
<span id="cb172-3"><a href="week-3-dictionary-based-approaches.html#cb172-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">media =</span> <span class="fu">ifelse</span>(<span class="fu">str_detect</span>(debate, <span class="st">&quot;abc&quot;</span>), <span class="st">&quot;ABC&quot;</span>, <span class="cn">NA</span>),</span>
<span id="cb172-4"><a href="week-3-dictionary-based-approaches.html#cb172-4" tabindex="-1"></a>         <span class="at">media =</span> <span class="fu">ifelse</span>(<span class="fu">str_detect</span>(debate, <span class="st">&quot;nbc&quot;</span>), <span class="st">&quot;NBC&quot;</span>, media),</span>
<span id="cb172-5"><a href="week-3-dictionary-based-approaches.html#cb172-5" tabindex="-1"></a>         <span class="at">media =</span> <span class="fu">ifelse</span>(<span class="fu">str_detect</span>(debate, <span class="st">&quot;fox&quot;</span>), <span class="st">&quot;FOX&quot;</span>, media)) <span class="sc">%&gt;%</span></span>
<span id="cb172-6"><a href="week-3-dictionary-based-approaches.html#cb172-6" tabindex="-1"></a>  <span class="fu">group_by</span>(media) <span class="sc">%&gt;%</span></span>
<span id="cb172-7"><a href="week-3-dictionary-based-approaches.html#cb172-7" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">median_sent =</span> <span class="fu">mean</span>(net_sent)) <span class="sc">%&gt;%</span></span>
<span id="cb172-8"><a href="week-3-dictionary-based-approaches.html#cb172-8" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>net_sent,<span class="at">color=</span>media,<span class="at">fill=</span>media)) <span class="sc">+</span></span>
<span id="cb172-9"><a href="week-3-dictionary-based-approaches.html#cb172-9" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">alpha =</span> <span class="fl">0.4</span>,</span>
<span id="cb172-10"><a href="week-3-dictionary-based-approaches.html#cb172-10" tabindex="-1"></a>                 <span class="at">binwidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb172-11"><a href="week-3-dictionary-based-approaches.html#cb172-11" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">wes_palette</span>(<span class="st">&quot;BottleRocket2&quot;</span>)) <span class="sc">+</span></span>
<span id="cb172-12"><a href="week-3-dictionary-based-approaches.html#cb172-12" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">wes_palette</span>(<span class="st">&quot;BottleRocket2&quot;</span>)) <span class="sc">+</span></span>
<span id="cb172-13"><a href="week-3-dictionary-based-approaches.html#cb172-13" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>media, <span class="at">ncol =</span> <span class="dv">1</span>) <span class="sc">+</span> </span>
<span id="cb172-14"><a href="week-3-dictionary-based-approaches.html#cb172-14" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> median_sent, <span class="at">color =</span> media), <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>)<span class="sc">+</span></span>
<span id="cb172-15"><a href="week-3-dictionary-based-approaches.html#cb172-15" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb172-16"><a href="week-3-dictionary-based-approaches.html#cb172-16" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position=</span><span class="st">&quot;bottom&quot;</span>) <span class="sc">+</span></span>
<span id="cb172-17"><a href="week-3-dictionary-based-approaches.html#cb172-17" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>,<span class="dv">5</span>)) <span class="sc">+</span></span>
<span id="cb172-18"><a href="week-3-dictionary-based-approaches.html#cb172-18" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Count&quot;</span>, <span class="at">color =</span> <span class="st">&quot;&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb172-19"><a href="week-3-dictionary-based-approaches.html#cb172-19" tabindex="-1"></a>       <span class="at">caption =</span> <span class="st">&quot;Note: Mean net sentiment in dashed lines.&quot;</span>)</span></code></pre></div>
<pre><code>## mutate: new variable &#39;media&#39; (character) with 3 unique values and 0% NA</code></pre>
<pre><code>## group_by: one grouping variable (media)</code></pre>
<pre><code>## mutate (grouped): new variable &#39;median_sent&#39; (double) with 3 unique values and 0% NA</code></pre>
<p><img src="main_files/figure-html/unnamed-chunk-46-1.png" width="672" /></p>
</div>
<div id="domain-specific-dictionaries" class="section level3" number="3.5.2">
<h3><span class="header-section-number">3.5.2</span> Domain-Specific Dictionaries</h3>
<p>Sentiment dictionaries are common. But you can make a dictionary of whatever concept you are interested in. After all, as long as you can create a lexicon (and validate it), then you can conduct an analysis similar to the one we just carried out. This time, rather than using an off-the-shelf (sentiment) dictionary, we will create our own. Let’s try a dictionary for two topics: the economy and migration.</p>
<p>As long as the dictionary has the same shape as our <code>nrc_pos_neg</code> object, we can follow the same process that we followed for the sentiment dictionaries.</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="week-3-dictionary-based-approaches.html#cb176-1" tabindex="-1"></a><span class="co"># First, we define the economy and migration as a concept, and then find words that signal that concept:</span></span>
<span id="cb176-2"><a href="week-3-dictionary-based-approaches.html#cb176-2" tabindex="-1"></a>economy <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(<span class="fu">c</span>(<span class="st">&quot;economy&quot;</span>,<span class="st">&quot;taxes&quot;</span>,<span class="st">&quot;inflation&quot;</span>,<span class="st">&quot;debt&quot;</span>,<span class="st">&quot;employment&quot;</span>,<span class="st">&quot;jobs&quot;</span>),<span class="st">&quot;economy&quot;</span>)</span>
<span id="cb176-3"><a href="week-3-dictionary-based-approaches.html#cb176-3" tabindex="-1"></a><span class="fu">colnames</span>(economy) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;word&quot;</span>,<span class="st">&quot;topic&quot;</span>)</span>
<span id="cb176-4"><a href="week-3-dictionary-based-approaches.html#cb176-4" tabindex="-1"></a>migration <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(<span class="fu">c</span>(<span class="st">&quot;immigrants&quot;</span>,<span class="st">&quot;border&quot;</span>,<span class="st">&quot;wall&quot;</span>,<span class="st">&quot;alien&quot;</span>,<span class="st">&quot;migrant&quot;</span>,<span class="st">&quot;visa&quot;</span>,<span class="st">&quot;daca&quot;</span>,<span class="st">&quot;dreamer&quot;</span>),<span class="st">&quot;migration&quot;</span>) </span>
<span id="cb176-5"><a href="week-3-dictionary-based-approaches.html#cb176-5" tabindex="-1"></a><span class="fu">colnames</span>(migration) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;word&quot;</span>,<span class="st">&quot;topic&quot;</span>)</span>
<span id="cb176-6"><a href="week-3-dictionary-based-approaches.html#cb176-6" tabindex="-1"></a></span>
<span id="cb176-7"><a href="week-3-dictionary-based-approaches.html#cb176-7" tabindex="-1"></a>dict <span class="ot">&lt;-</span> <span class="fu">rbind.data.frame</span>(economy,migration)</span>
<span id="cb176-8"><a href="week-3-dictionary-based-approaches.html#cb176-8" tabindex="-1"></a>dict</span></code></pre></div>
<pre><code>##          word     topic
## 1     economy   economy
## 2       taxes   economy
## 3   inflation   economy
## 4        debt   economy
## 5  employment   economy
## 6        jobs   economy
## 7  immigrants migration
## 8      border migration
## 9        wall migration
## 10      alien migration
## 11    migrant migration
## 12       visa migration
## 13       daca migration
## 14    dreamer migration</code></pre>
<p>Let’s see if we find some of these words in our comments:</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="week-3-dictionary-based-approaches.html#cb178-1" tabindex="-1"></a>ventura_topic <span class="ot">&lt;-</span> tidy_ventura <span class="sc">%&gt;%</span></span>
<span id="cb178-2"><a href="week-3-dictionary-based-approaches.html#cb178-2" tabindex="-1"></a>  <span class="fu">left_join</span>(dict)</span></code></pre></div>
<pre><code>## Joining with `by = join_by(word)`
## left_join: added one column (topic)
## &gt; rows only in x 196,175
## &gt; rows only in y ( 3)
## &gt; matched rows 1,373
## &gt; =========
## &gt; rows total 197,548</code></pre>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="week-3-dictionary-based-approaches.html#cb180-1" tabindex="-1"></a>ventura_topic <span class="sc">%&gt;%</span></span>
<span id="cb180-2"><a href="week-3-dictionary-based-approaches.html#cb180-2" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="sc">!</span><span class="fu">is.na</span>(topic)) <span class="sc">%&gt;%</span></span>
<span id="cb180-3"><a href="week-3-dictionary-based-approaches.html#cb180-3" tabindex="-1"></a>  <span class="fu">group_by</span>(topic) <span class="sc">%&gt;%</span></span>
<span id="cb180-4"><a href="week-3-dictionary-based-approaches.html#cb180-4" tabindex="-1"></a>  <span class="fu">count</span>(word, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## filter: removed 196,175 rows (99%), 1,373 rows remaining
## group_by: one grouping variable (topic)
## count: now 11 rows and 3 columns, one group variable remaining (topic)</code></pre>
<pre><code>## # A tibble: 11 × 3
## # Groups:   topic [2]
##    topic     word           n
##    &lt;chr&gt;     &lt;chr&gt;      &lt;int&gt;
##  1 economy   taxes        680
##  2 economy   economy      328
##  3 economy   jobs         273
##  4 migration wall          34
##  5 economy   debt          32
##  6 migration immigrants    12
##  7 migration border         7
##  8 economy   employment     3
##  9 migration alien          2
## 10 migration daca           1
## 11 migration visa           1</code></pre>
<p>Not that many. Note that we did not stem or lemmatized our corpus, so in order to get ‘job’ <em>and</em> ‘jobs’ we must have both in our dictionary. That means that the same pre-processing step that we carry our in our corpus, we must also carry our in our dictionary.</p>
<p>If you are a bit more versed in R language, you will notice that dictionaries are actually lists. <code>quanteda</code> understand dictionaries as lists so we can actually build them as such and use its function <code>likcalike()</code> to find words in text. The added benefit is that we can use <a href="https://linuxhint.com/bash_globbing_tutorial/">glob</a> to find variations of the same word (e.g., <code>job*</code> will match ‘job’ and ‘jobs’ and ‘jobless’).</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="week-3-dictionary-based-approaches.html#cb183-1" tabindex="-1"></a>dict <span class="ot">&lt;-</span> <span class="fu">dictionary</span>(<span class="fu">list</span>(<span class="at">economy =</span> <span class="fu">c</span>(<span class="st">&quot;econom*&quot;</span>,<span class="st">&quot;tax*&quot;</span>,<span class="st">&quot;inflation&quot;</span>,<span class="st">&quot;debt*&quot;</span>,<span class="st">&quot;employ*&quot;</span>,<span class="st">&quot;job*&quot;</span>),</span>
<span id="cb183-2"><a href="week-3-dictionary-based-approaches.html#cb183-2" tabindex="-1"></a>                        <span class="at">immigration =</span> <span class="fu">c</span>(<span class="st">&quot;immigrant*&quot;</span>,<span class="st">&quot;border&quot;</span>,<span class="st">&quot;wall&quot;</span>,<span class="st">&quot;alien&quot;</span>,<span class="st">&quot;migrant*&quot;</span>,<span class="st">&quot;visa*&quot;</span>,<span class="st">&quot;daca&quot;</span>,<span class="st">&quot;dreamer*&quot;</span>))) </span>
<span id="cb183-3"><a href="week-3-dictionary-based-approaches.html#cb183-3" tabindex="-1"></a></span>
<span id="cb183-4"><a href="week-3-dictionary-based-approaches.html#cb183-4" tabindex="-1"></a><span class="co"># liwcalike lowercases input text</span></span>
<span id="cb183-5"><a href="week-3-dictionary-based-approaches.html#cb183-5" tabindex="-1"></a>ventura_topics <span class="ot">&lt;-</span> <span class="fu">liwcalike</span>(ventura_etal_df<span class="sc">$</span>comments,</span>
<span id="cb183-6"><a href="week-3-dictionary-based-approaches.html#cb183-6" tabindex="-1"></a>                               <span class="at">dictionary =</span> dict)</span>
<span id="cb183-7"><a href="week-3-dictionary-based-approaches.html#cb183-7" tabindex="-1"></a></span>
<span id="cb183-8"><a href="week-3-dictionary-based-approaches.html#cb183-8" tabindex="-1"></a><span class="co"># liwcalike keeps the order so we can cbind them directly</span></span>
<span id="cb183-9"><a href="week-3-dictionary-based-approaches.html#cb183-9" tabindex="-1"></a>topics <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(ventura_etal_df,ventura_topics) </span>
<span id="cb183-10"><a href="week-3-dictionary-based-approaches.html#cb183-10" tabindex="-1"></a></span>
<span id="cb183-11"><a href="week-3-dictionary-based-approaches.html#cb183-11" tabindex="-1"></a><span class="co"># Look only at the comments that mention the economy and immigration</span></span>
<span id="cb183-12"><a href="week-3-dictionary-based-approaches.html#cb183-12" tabindex="-1"></a><span class="fu">head</span>(topics[topics<span class="sc">$</span>economy<span class="sc">&gt;</span><span class="dv">0</span> <span class="sc">&amp;</span> topics<span class="sc">$</span>immigration<span class="sc">&gt;</span><span class="dv">0</span>,])</span></code></pre></div>
<pre><code>##       text_id
## 4998     4999
## 6475     6477
## 8098     8113
## 12331   32211
## 14345   34225
## 19889   62164
##                                                                                                                                              comments
## 4998                           Trump is going to create jobs to finish that wall,  hows that working for ya?  I don’t see Mexico paying for it either
## 6475                           Trump is trash illegal immigrants pay more taxes than this man and you guys support this broke failure con billionaire
## 8098                                  $750.00 in taxes in two years?????   BUT HE&#39;S ALL OVER THE PLACE INSULTING IMMIGRANTS WHO PAID MORE IN TAXES!!!
## 12331    Ask\n Biden how much he will raise taxes to pay for all the things he says he\n is going to provide everyone - including illegal immigrants!
## 14345 Trump has been living the life and does not care for the hard working American...His taxes are not the only rip off...Investigate Wall Money...
## 19889                                                               Vote trump out. He needs to pay taxes too ... immigrants pay more than that thief
##                        id likes                  debate   docname Segment
## 4998         Ellen Lustic    NA abc_first_debate_manual  text4998    4998
## 6475      Kevin G Vazquez     1 abc_first_debate_manual  text6475    6475
## 8098      Prince M Dorbor     1 abc_first_debate_manual  text8098    8098
## 12331 Lynne Basista Shine     6 fox_first_debate_manual text12331   12331
## 14345          RJ Jimenez     4 fox_first_debate_manual text14345   14345
## 19889      Nicole Brennan    13 nbc_first_debate_manual text19889   19889
##            WPS WC Sixltr   Dic economy immigration AllPunc Period Comma Colon
## 4998  12.50000 25   4.00  8.00    4.00        4.00   12.00   0.00     4     0
## 6475  20.00000 20  25.00 10.00    5.00        5.00    0.00   0.00     0     0
## 8098  14.00000 28   7.14 10.71    7.14        3.57   35.71   3.57     0     0
## 12331 27.00000 27  18.52  7.41    3.70        3.70    7.41   0.00     0     0
## 14345 11.66667 35   8.57  5.71    2.86        2.86   25.71  25.71     0     0
## 19889  9.50000 19   5.26 10.53    5.26        5.26   21.05  21.05     0     0
##       SemiC QMark Exclam Dash Quote Apostro Parenth OtherP
## 4998      0  4.00   0.00  0.0  4.00    4.00       0   8.00
## 6475      0  0.00   0.00  0.0  0.00    0.00       0   0.00
## 8098      0 17.86  10.71  0.0  3.57    3.57       0  35.71
## 12331     0  0.00   3.70  3.7  0.00    0.00       0   3.70
## 14345     0  0.00   0.00  0.0  0.00    0.00       0  25.71
## 19889     0  0.00   0.00  0.0  0.00    0.00       0  21.05</code></pre>
<p>The output provides some interesting information. First, <code>economy</code> and <code>immigration</code> gives us the <em>percentage</em> of words in the text that are about the economy or immigration. In general, we would not expect too many words in a sentence to mention, for example, ‘jobs’ to argue that the sentences talks about the economy. So, any number above 0% can be counted as mentioning the economy (unless you have some theoretical grounds where 3% of words mentioning the economy &gt; 2% of words mentioning the economy). For the rest of variables:</p>
<ul>
<li><code>WPS</code>: Words per sentence.</li>
<li><code>WC</code>: Word count.</li>
<li><code>Sixltr</code>: Six-letter words (%).</li>
<li><code>Dic</code>: % of words in the dictionary.</li>
<li><code>Allpunct</code>: % of all punctuation marks.</li>
<li><code>Period</code> to <code>OtherP</code>: % of specific punctuation marks.</li>
</ul>
<p>With the information obtained, we can find which users were focused more on what topic:</p>
<pre><code>## mutate: new variable &#39;media&#39; (character) with 3 unique values and 0% NA</code></pre>
<pre><code>##         new variable &#39;economy_dum&#39; (double) with 2 unique values and 0% NA</code></pre>
<pre><code>##         new variable &#39;immigration_dum&#39; (double) with 2 unique values and 0% NA</code></pre>
<pre><code>## group_by: one grouping variable (media)</code></pre>
<pre><code>## mutate (grouped): new variable &#39;pct_econ&#39; (double) with 3 unique values and 0% NA</code></pre>
<pre><code>##                   new variable &#39;pct_migr&#39; (double) with 3 unique values and 0% NA</code></pre>
<pre><code>## distinct (grouped): removed 29,544 rows (&gt;99%), 3 rows remaining</code></pre>
<table>
<caption>
<span id="tab:unnamed-chunk-50">Table 3.1: </span>% of mentions by topic and media outlet.
</caption>
<thead>
<tr>
<th style="text-align:left;">
media
</th>
<th style="text-align:right;">
pct_econ
</th>
<th style="text-align:right;">
pct_migr
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
ABC
</td>
<td style="text-align:right;">
0.0641299
</td>
<td style="text-align:right;">
0.0030441
</td>
</tr>
<tr>
<td style="text-align:left;">
FOX
</td>
<td style="text-align:right;">
0.0856325
</td>
<td style="text-align:right;">
0.0008175
</td>
</tr>
<tr>
<td style="text-align:left;">
NBC
</td>
<td style="text-align:right;">
0.0708661
</td>
<td style="text-align:right;">
0.0018171
</td>
</tr>
</tbody>
</table>
</div>
<div id="using-pre-built-dictionaries" class="section level3" number="3.5.3">
<h3><span class="header-section-number">3.5.3</span> Using Pre-Built Dictionaries</h3>
<p>So far we have seen how to apply pre-loaded dictionaries (e.g., sentiment) and our own dictionaries. What if you have a pre-built dictionary that you want to apply to your corpus? As long as the pre-built dictionary has the correct shape, we can use the techniques we have applied so far. This also means that you will need to do some data-wrangling as pre-built dictionaries will come in different shapes.</p>
<p>Let’s use the NRC Affect Intensity Lexicon (created by the same people who made the pre-loaded <code>nrc</code> sentiment dictionary). The NRC Affect Intensity Lexicon measure the intensity of an emotion in a scale of 0 (low) to 1 (high). For example, ‘defiance’ has an anger intensity of 0.51 and ‘hate’ an anger intensity of 0.83.</p>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb192-1"><a href="week-3-dictionary-based-approaches.html#cb192-1" tabindex="-1"></a>intense_lex <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="at">file =</span> <span class="st">&quot;data/NRC-AffectIntensity-Lexicon.txt&quot;</span>, <span class="at">fill =</span> <span class="cn">TRUE</span>,</span>
<span id="cb192-2"><a href="week-3-dictionary-based-approaches.html#cb192-2" tabindex="-1"></a>                          <span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb192-3"><a href="week-3-dictionary-based-approaches.html#cb192-3" tabindex="-1"></a><span class="fu">head</span>(intense_lex)</span></code></pre></div>
<pre><code>##         term score AffectDimension
## 1   outraged 0.964           anger
## 2  brutality 0.959           anger
## 3     hatred 0.953           anger
## 4    hateful 0.940           anger
## 5  terrorize 0.939           anger
## 6 infuriated 0.938           anger</code></pre>
<p>This is more than a dictionary, and the best use of it to include the intensity of each word to obtain more variation in our analysis of the text (e.g., rather than showing anger-no anger, we can analyze a degree of anger). We will use the <code>tidytext</code> approach to analyze the degrees of ‘joy’ in our corpus.</p>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb194-1"><a href="week-3-dictionary-based-approaches.html#cb194-1" tabindex="-1"></a>joy_lex <span class="ot">&lt;-</span> intense_lex <span class="sc">%&gt;%</span></span>
<span id="cb194-2"><a href="week-3-dictionary-based-approaches.html#cb194-2" tabindex="-1"></a>  <span class="fu">filter</span>(AffectDimension<span class="sc">==</span><span class="st">&quot;joy&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb194-3"><a href="week-3-dictionary-based-approaches.html#cb194-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">word=</span>term) <span class="sc">%&gt;%</span></span>
<span id="cb194-4"><a href="week-3-dictionary-based-approaches.html#cb194-4" tabindex="-1"></a>  <span class="fu">select</span>(word,AffectDimension,score)</span></code></pre></div>
<pre><code>## filter: removed 4,546 rows (78%), 1,268 rows remaining</code></pre>
<pre><code>## mutate: new variable &#39;word&#39; (character) with 1,268 unique values and 0% NA</code></pre>
<pre><code>## select: dropped one variable (term)</code></pre>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb198-1"><a href="week-3-dictionary-based-approaches.html#cb198-1" tabindex="-1"></a>ventura_joy <span class="ot">&lt;-</span> tidy_ventura <span class="sc">%&gt;%</span></span>
<span id="cb198-2"><a href="week-3-dictionary-based-approaches.html#cb198-2" tabindex="-1"></a>  <span class="fu">left_join</span>(joy_lex) <span class="sc">%&gt;%</span></span>
<span id="cb198-3"><a href="week-3-dictionary-based-approaches.html#cb198-3" tabindex="-1"></a>  <span class="do">## Most of the comments have no joy words so we will change these NAs to 0 but this is an ad-hoc decision. This decision must be theoretically motivated and justified</span></span>
<span id="cb198-4"><a href="week-3-dictionary-based-approaches.html#cb198-4" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">score =</span> <span class="fu">ifelse</span>(<span class="fu">is.na</span>(score),<span class="dv">0</span>,score))</span></code></pre></div>
<pre><code>## Joining with `by = join_by(word)`</code></pre>
<pre><code>## left_join: added 2 columns (AffectDimension, score)</code></pre>
<pre><code>##            &gt; rows only in x   184,943</code></pre>
<pre><code>##            &gt; rows only in y  (    769)</code></pre>
<pre><code>##            &gt; matched rows      12,605</code></pre>
<pre><code>##            &gt;                 =========</code></pre>
<pre><code>##            &gt; rows total       197,548</code></pre>
<pre><code>## mutate: changed 184,943 values (94%) of &#39;score&#39; (184943 fewer NA)</code></pre>
<div class="sourceCode" id="cb207"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb207-1"><a href="week-3-dictionary-based-approaches.html#cb207-1" tabindex="-1"></a><span class="fu">head</span>(ventura_joy[ventura_joy<span class="sc">$</span>score<span class="sc">&gt;</span><span class="dv">0</span>,])</span></code></pre></div>
<pre><code>##    text_id           id likes                  debate       word
## 18       2   Anita Hill    61 abc_first_debate_manual        god
## 19       2   Anita Hill    61 abc_first_debate_manual      bless
## 23       3 Dave Garland    99 abc_first_debate_manual     living
## 30       4     Carl Roy    47 abc_first_debate_manual      laugh
## 64       8  Tammy Eisen    39 abc_first_debate_manual experience
## 65       8  Tammy Eisen    39 abc_first_debate_manual      share
##    AffectDimension score
## 18             joy 0.545
## 19             joy 0.561
## 23             joy 0.312
## 30             joy 0.891
## 64             joy 0.375
## 65             joy 0.438</code></pre>
<p>Now, we can see the relationship between <code>likes</code> and <code>joy</code>:</p>
<div class="sourceCode" id="cb209"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb209-1"><a href="week-3-dictionary-based-approaches.html#cb209-1" tabindex="-1"></a><span class="fu">library</span>(MASS) <span class="co"># To add the negative binomial fitted line</span></span></code></pre></div>
<pre><code>## 
## Attaching package: &#39;MASS&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:tidylog&#39;:
## 
##     select</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     select</code></pre>
<div class="sourceCode" id="cb213"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb213-1"><a href="week-3-dictionary-based-approaches.html#cb213-1" tabindex="-1"></a>ventura_joy <span class="sc">%&gt;%</span></span>
<span id="cb213-2"><a href="week-3-dictionary-based-approaches.html#cb213-2" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">media =</span> <span class="fu">ifelse</span>(<span class="fu">str_detect</span>(debate, <span class="st">&quot;abc&quot;</span>), <span class="st">&quot;ABC&quot;</span>, <span class="cn">NA</span>),</span>
<span id="cb213-3"><a href="week-3-dictionary-based-approaches.html#cb213-3" tabindex="-1"></a>         <span class="at">media =</span> <span class="fu">ifelse</span>(<span class="fu">str_detect</span>(debate, <span class="st">&quot;nbc&quot;</span>), <span class="st">&quot;NBC&quot;</span>, media),</span>
<span id="cb213-4"><a href="week-3-dictionary-based-approaches.html#cb213-4" tabindex="-1"></a>         <span class="at">media =</span> <span class="fu">ifelse</span>(<span class="fu">str_detect</span>(debate, <span class="st">&quot;fox&quot;</span>), <span class="st">&quot;FOX&quot;</span>, media)) <span class="sc">%&gt;%</span></span>
<span id="cb213-5"><a href="week-3-dictionary-based-approaches.html#cb213-5" tabindex="-1"></a>  <span class="co"># Calculate mean joy in each comment</span></span>
<span id="cb213-6"><a href="week-3-dictionary-based-approaches.html#cb213-6" tabindex="-1"></a>  <span class="fu">group_by</span>(text_id) <span class="sc">%&gt;%</span></span>
<span id="cb213-7"><a href="week-3-dictionary-based-approaches.html#cb213-7" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">mean_joy =</span> <span class="fu">mean</span>(score)) <span class="sc">%&gt;%</span></span>
<span id="cb213-8"><a href="week-3-dictionary-based-approaches.html#cb213-8" tabindex="-1"></a>  <span class="fu">distinct</span>(text_id,mean_joy,likes,media) <span class="sc">%&gt;%</span></span>
<span id="cb213-9"><a href="week-3-dictionary-based-approaches.html#cb213-9" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb213-10"><a href="week-3-dictionary-based-approaches.html#cb213-10" tabindex="-1"></a>  <span class="co"># Let&#39;s only look at comments that had SOME joy in them</span></span>
<span id="cb213-11"><a href="week-3-dictionary-based-approaches.html#cb213-11" tabindex="-1"></a>  <span class="fu">filter</span>(mean_joy <span class="sc">&gt;</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span></span>
<span id="cb213-12"><a href="week-3-dictionary-based-approaches.html#cb213-12" tabindex="-1"></a>  <span class="co"># Remove the ones people like too much</span></span>
<span id="cb213-13"><a href="week-3-dictionary-based-approaches.html#cb213-13" tabindex="-1"></a>  <span class="fu">filter</span>(likes <span class="sc">&lt;</span> <span class="dv">26</span>) <span class="sc">%&gt;%</span></span>
<span id="cb213-14"><a href="week-3-dictionary-based-approaches.html#cb213-14" tabindex="-1"></a>  <span class="co"># Plot</span></span>
<span id="cb213-15"><a href="week-3-dictionary-based-approaches.html#cb213-15" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>mean_joy,<span class="at">y=</span>likes,<span class="at">color=</span>media,<span class="at">fill=</span>media)) <span class="sc">+</span></span>
<span id="cb213-16"><a href="week-3-dictionary-based-approaches.html#cb213-16" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.3</span>) <span class="sc">+</span></span>
<span id="cb213-17"><a href="week-3-dictionary-based-approaches.html#cb213-17" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;glm.nb&quot;</span>) <span class="sc">+</span></span>
<span id="cb213-18"><a href="week-3-dictionary-based-approaches.html#cb213-18" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">wes_palette</span>(<span class="st">&quot;BottleRocket2&quot;</span>)) <span class="sc">+</span></span>
<span id="cb213-19"><a href="week-3-dictionary-based-approaches.html#cb213-19" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">wes_palette</span>(<span class="st">&quot;BottleRocket2&quot;</span>)) <span class="sc">+</span></span>
<span id="cb213-20"><a href="week-3-dictionary-based-approaches.html#cb213-20" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>media, <span class="at">ncol =</span> <span class="dv">1</span>) <span class="sc">+</span> </span>
<span id="cb213-21"><a href="week-3-dictionary-based-approaches.html#cb213-21" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb213-22"><a href="week-3-dictionary-based-approaches.html#cb213-22" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position=</span><span class="st">&quot;none&quot;</span>) <span class="sc">+</span></span>
<span id="cb213-23"><a href="week-3-dictionary-based-approaches.html#cb213-23" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Mean Joy&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Likes&quot;</span>, <span class="at">color =</span> <span class="st">&quot;&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;&quot;</span>)</span></code></pre></div>
<pre><code>## mutate: new variable &#39;media&#39; (character) with 3 unique values and 0% NA</code></pre>
<pre><code>## group_by: one grouping variable (text_id)</code></pre>
<pre><code>## mutate (grouped): new variable &#39;mean_joy&#39; (double) with 3,118 unique values and 0% NA</code></pre>
<pre><code>## distinct (grouped): removed 168,013 rows (85%), 29,535 rows remaining</code></pre>
<pre><code>## ungroup: no grouping variables</code></pre>
<pre><code>## filter: removed 20,355 rows (69%), 9,180 rows remaining</code></pre>
<pre><code>## filter: removed 2,518 rows (27%), 6,662 rows remaining</code></pre>
<pre><code>## `geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
<p><img src="main_files/figure-html/unnamed-chunk-53-1.png" width="672" /></p>
<p>Finally, for the sake of showing the process, I will write the code to load the dictionary using <code>quanteda</code>, but note that this approach loses all the intensity information.</p>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="week-3-dictionary-based-approaches.html#cb222-1" tabindex="-1"></a>affect_dict <span class="ot">&lt;-</span> <span class="fu">dictionary</span>(<span class="fu">list</span>(<span class="at">anger =</span> intense_lex<span class="sc">$</span>term[intense_lex<span class="sc">$</span>AffectDimension<span class="sc">==</span><span class="st">&quot;anger&quot;</span>],</span>
<span id="cb222-2"><a href="week-3-dictionary-based-approaches.html#cb222-2" tabindex="-1"></a>                        <span class="at">fear =</span> intense_lex<span class="sc">$</span>term[intense_lex<span class="sc">$</span>AffectDimension<span class="sc">==</span><span class="st">&quot;fear&quot;</span>],</span>
<span id="cb222-3"><a href="week-3-dictionary-based-approaches.html#cb222-3" tabindex="-1"></a>                        <span class="at">joy =</span> intense_lex<span class="sc">$</span>term[intense_lex<span class="sc">$</span>AffectDimension<span class="sc">==</span><span class="st">&quot;joy&quot;</span>],</span>
<span id="cb222-4"><a href="week-3-dictionary-based-approaches.html#cb222-4" tabindex="-1"></a>                        <span class="at">sadness =</span> intense_lex<span class="sc">$</span>term[intense_lex<span class="sc">$</span>AffectDimension<span class="sc">==</span><span class="st">&quot;sadness&quot;</span>])) </span>
<span id="cb222-5"><a href="week-3-dictionary-based-approaches.html#cb222-5" tabindex="-1"></a></span>
<span id="cb222-6"><a href="week-3-dictionary-based-approaches.html#cb222-6" tabindex="-1"></a>ventura_affect <span class="ot">&lt;-</span> <span class="fu">liwcalike</span>(ventura_etal_df<span class="sc">$</span>comments,</span>
<span id="cb222-7"><a href="week-3-dictionary-based-approaches.html#cb222-7" tabindex="-1"></a>                               <span class="at">dictionary =</span> affect_dict)</span>
<span id="cb222-8"><a href="week-3-dictionary-based-approaches.html#cb222-8" tabindex="-1"></a></span>
<span id="cb222-9"><a href="week-3-dictionary-based-approaches.html#cb222-9" tabindex="-1"></a><span class="co"># liwcalike keeps the order so we can cbind them directly</span></span>
<span id="cb222-10"><a href="week-3-dictionary-based-approaches.html#cb222-10" tabindex="-1"></a>affect <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(ventura_etal_df,ventura_affect) </span>
<span id="cb222-11"><a href="week-3-dictionary-based-approaches.html#cb222-11" tabindex="-1"></a></span>
<span id="cb222-12"><a href="week-3-dictionary-based-approaches.html#cb222-12" tabindex="-1"></a><span class="co"># Look only at the comments that have anger and fear</span></span>
<span id="cb222-13"><a href="week-3-dictionary-based-approaches.html#cb222-13" tabindex="-1"></a><span class="fu">head</span>(affect[affect<span class="sc">$</span>anger<span class="sc">&gt;</span><span class="dv">0</span> <span class="sc">&amp;</span> affect<span class="sc">$</span>fear<span class="sc">&gt;</span><span class="dv">0</span>,])</span></code></pre></div>
<pre><code>##    text_id
## 3        3
## 7        7
## 9        9
## 11      11
## 12      12
## 23      23
##                                                                                                                                                                                       comments
## 3                                                                               Trump  is  a  living  disaster!    What  an embarrassment  to  all  human  beings!    The  man  is  dangerous!
## 7                                                                                  What happened to the days when it was a debate not a bully session! I am so ashamed of this administration!
## 9  ......\n a smart president?  A thief, a con man, and a liar that has taken tax \npayers money to his own properties.  A liar that knew the magnitude of \nthe virus and did not address it.
## 11                             with\n the usa having such a bad opiate problem then trump brings up about \nbidens son is the most disgraceful thing any human being could do...vote\n him out
## 12   Trump’s\n only recourse in the debate is to demean his opponent and talk about \nwhat a great man he, himself is. Turn his mic off when it’s not his turn\n to speak. Nothing but babble!
## 23                                                                                           Trump such a hateful person he has no moral or respect in a debate he blames everyone except him.
##              id likes                  debate docname Segment       WPS WC
## 3  Dave Garland    99 abc_first_debate_manual   text3       3  6.333333 19
## 7   Connie Sage    79 abc_first_debate_manual   text7       7 11.500000 23
## 9  Susan Weyant    53 abc_first_debate_manual   text9       9 15.333333 46
## 11  Lynn Kohler    41 abc_first_debate_manual  text11      11 32.000000 32
## 12     Jim Lape    28 abc_first_debate_manual  text12      12 13.000000 39
## 23   Joe Sonera    65 abc_first_debate_manual  text23      23 20.000000 20
##    Sixltr   Dic anger  fear  joy sadness AllPunc Period Comma Colon SemiC QMark
## 3   15.79 36.84  5.26 15.79 5.26   10.53   15.79   0.00  0.00     0     0  0.00
## 7   17.39 17.39  4.35  4.35 0.00    8.70    8.70   0.00  0.00     0     0  0.00
## 9    8.70 13.04  4.35  2.17 2.17    4.35   23.91  17.39  4.35     0     0  2.17
## 11   6.25 28.12  9.38  6.25 3.12    9.38    9.38   9.38  0.00     0     0  0.00
## 12  12.82  5.13  2.56  2.56 0.00    0.00   15.38   5.13  2.56     0     0  0.00
## 23  15.00 25.00 10.00  5.00 5.00    5.00    5.00   5.00  0.00     0     0  0.00
##    Exclam Dash Quote Apostro Parenth OtherP
## 3   15.79    0  0.00    0.00       0  15.79
## 7    8.70    0  0.00    0.00       0   8.70
## 9    0.00    0  0.00    0.00       0  23.91
## 11   0.00    0  0.00    0.00       0   9.38
## 12   2.56    0  5.13    5.13       0  10.26
## 23   0.00    0  0.00    0.00       0   5.00</code></pre>
</div>
</div>
<div id="homework" class="section level2" number="3.6">
<h2><span class="header-section-number">3.6</span> Homework</h2>
<ol style="list-style-type: decimal">
<li>Replicate the results from the left-most column of Figure 3 in Ventura et al. (2021)</li>
<li>Look at the keywords in context for <em>Biden</em> in the <code>ventura_etal_df</code> dataset, and compare the results with the same data, but pre-processed (i.e., lower-case, remove stopwords, etc.). Which provides more information about the context in which <em>Biden</em> appears in the comments?</li>
<li>Do a different collocation approach with the <code>ventura_etal_df</code> dataset, but pre-process the data (i.e., lower-case, remove stopwords, etc.). Which approach (pre-processed and not pre-processed) provides a better picture of the corpus or of the collocations you found?</li>
<li>Compare the <strong>positive</strong> sentiments of comments mentioning <em>trump</em> and comments mentioning <em>biden</em> obtained using <code>bing</code> and <code>afinn</code>. Note that <code>afinn</code> gives a numeric value, so you will need to choose a threshold to determine <strong>positive</strong> sentiment.</li>
<li>Using <code>bing</code>, compare the sentiment of comments mentioning <em>trump</em> and comments mentioning <em>biden</em> using different metrics (e.g., Young and Soroka 2012, Martins and Baumard 2020, Ventura et al. 2021).</li>
<li>Create your own domain-specific dictionary and apply it to the <code>ventura_etal_df</code> dataset. Show the limitation of your dictionary (e.g., false positives) and comment on how much of a problem this would be if you wanted to conduct an analysis of this corpus.</li>
</ol>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="4">
<li id="fn4"><p>This code is adapted from Christopher Barrie’s course on <a href="https://cjbarrie.github.io/CTA-ED/exercise-2-dictionary-based-methods.html">Computational Text Analysis</a>.<a href="week-3-dictionary-based-approaches.html#fnref4" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
  </main>

  <div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page">
      <h2>On this page</h2>
      <div id="book-on-this-page"></div>

      <div class="book-extra">
        <ul class="list-unstyled">
          <li><a id="book-source" href="#">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="#">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
      </div>
    </nav>
  </div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5">
  <div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>PS9594A: Computational Text Analysis</strong>" was written by Dr. Sebastián Vallejo Vera | Western University. It was last built on 2024-01-26.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
<script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>

</html>
